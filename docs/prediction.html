<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Prediction | House Prices Advanced Regression Techniques</title>
  <meta name="description" content="This is a project based on a getting started Kaggle competition House Prices - Advanced Regression Techniques." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Prediction | House Prices Advanced Regression Techniques" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a project based on a getting started Kaggle competition House Prices - Advanced Regression Techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Prediction | House Prices Advanced Regression Techniques" />
  
  <meta name="twitter:description" content="This is a project based on a getting started Kaggle competition House Prices - Advanced Regression Techniques." />
  

<meta name="author" content="Yanet Gomez" />


<meta name="date" content="2021-09-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modeling.html"/>
<link rel="next" href="conclusion.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">House Prices: Advanced Regression Techniques</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="origin.html"><a href="origin.html"><i class="fa fa-check"></i><b>2</b> Origin</a><ul>
<li class="chapter" data-level="2.1" data-path="origin.html"><a href="origin.html#starting-point"><i class="fa fa-check"></i><b>2.1</b> Starting Point</a></li>
<li class="chapter" data-level="2.2" data-path="origin.html"><a href="origin.html#technical-skills"><i class="fa fa-check"></i><b>2.2</b> Technical Skills</a></li>
<li class="chapter" data-level="2.3" data-path="origin.html"><a href="origin.html#problem-definition"><i class="fa fa-check"></i><b>2.3</b> Problem Definition</a></li>
<li class="chapter" data-level="2.4" data-path="origin.html"><a href="origin.html#data-analytics-workflow"><i class="fa fa-check"></i><b>2.4</b> Data Analytics Workflow</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Data</a></li>
<li class="chapter" data-level="4" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>4</b> Data Pre-processing</a><ul>
<li class="chapter" data-level="4.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#identifying-and-correcting-missing-values"><i class="fa fa-check"></i><b>4.1</b> Identifying and Correcting Missing Values</a><ul>
<li class="chapter" data-level="4.1.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#detect-missing-values"><i class="fa fa-check"></i><b>4.1.1</b> Detect Missing Values</a></li>
<li class="chapter" data-level="4.1.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#dealing-with-missing-values"><i class="fa fa-check"></i><b>4.1.2</b> Dealing With Missing Values</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#correct-data-types"><i class="fa fa-check"></i><b>4.2</b> Correct Data Types</a></li>
<li class="chapter" data-level="4.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#feature-transformation"><i class="fa fa-check"></i><b>4.3</b> Feature Transformation</a><ul>
<li class="chapter" data-level="4.3.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#visualizing-the-distribution-and-spread-of-target-feature-salesprice"><i class="fa fa-check"></i><b>4.3.1</b> Visualizing the Distribution and Spread of Target Feature: SalesPrice</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#features-highly-correlated-with-sales-price"><i class="fa fa-check"></i><b>4.3.2</b> Features Highly Correlated with Sales Price</a></li>
<li class="chapter" data-level="4.3.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#attribute-construction-from-year-features"><i class="fa fa-check"></i><b>4.3.3</b> Attribute Construction from Year Features</a></li>
<li class="chapter" data-level="4.3.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#reducing-levels-by-grouping-unrepresented-categories"><i class="fa fa-check"></i><b>4.3.4</b> Reducing Levels by Grouping Unrepresented Categories</a></li>
<li class="chapter" data-level="4.3.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#attribute-construction-by-combining-some-features-to-make-new-features."><i class="fa fa-check"></i><b>4.3.5</b> Attribute Construction by Combining some Features to make New Features.</a></li>
<li class="chapter" data-level="4.3.6" data-path="data-pre-processing.html"><a href="data-pre-processing.html#attribute-construction-by-binning"><i class="fa fa-check"></i><b>4.3.6</b> Attribute Construction by Binning</a></li>
<li class="chapter" data-level="4.3.7" data-path="data-pre-processing.html"><a href="data-pre-processing.html#new-variables-by-interactions"><i class="fa fa-check"></i><b>4.3.7</b> New Variables by Interactions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#dimensionality-and-numerosity-reduction"><i class="fa fa-check"></i><b>4.4</b> Dimensionality and Numerosity Reduction</a><ul>
<li class="chapter" data-level="4.4.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#outliers"><i class="fa fa-check"></i><b>4.4.1</b> Outliers</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="modeling.html"><a href="modeling.html"><i class="fa fa-check"></i><b>5</b> Modeling</a><ul>
<li class="chapter" data-level="5.1" data-path="modeling.html"><a href="modeling.html#multivariate-linear-regression-model"><i class="fa fa-check"></i><b>5.1</b> Multivariate Linear Regression Model</a></li>
<li class="chapter" data-level="5.2" data-path="modeling.html"><a href="modeling.html#model-selection"><i class="fa fa-check"></i><b>5.2</b> Model Selection</a></li>
<li class="chapter" data-level="5.3" data-path="modeling.html"><a href="modeling.html#regularized-regression-models"><i class="fa fa-check"></i><b>5.3</b> Regularized Regression Models</a><ul>
<li class="chapter" data-level="5.3.1" data-path="modeling.html"><a href="modeling.html#identify-the-optimal-lambda-parameter"><i class="fa fa-check"></i><b>5.3.1</b> Identify the Optimal Lambda Parameter</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="modeling.html"><a href="modeling.html#training-the-regularized-regression-models"><i class="fa fa-check"></i><b>5.4</b> Training the Regularized Regression Models</a></li>
<li class="chapter" data-level="5.5" data-path="modeling.html"><a href="modeling.html#evaluating-the-regularized-regression-models-performance"><i class="fa fa-check"></i><b>5.5</b> Evaluating the Regularized Regression Models’ Performance</a></li>
<li class="chapter" data-level="5.6" data-path="modeling.html"><a href="modeling.html#training-xgboost-model-with-feature-selection"><i class="fa fa-check"></i><b>5.6</b> Training XGBoost Model with Feature Selection</a><ul>
<li class="chapter" data-level="5.6.1" data-path="modeling.html"><a href="modeling.html#training-the-xgboost-model"><i class="fa fa-check"></i><b>5.6.1</b> Training the XGboost Model</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="modeling.html"><a href="modeling.html#evaluating-xgboost-models-performance"><i class="fa fa-check"></i><b>5.7</b> Evaluating XGBoost Model’s Performance</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>6</b> Prediction</a><ul>
<li class="chapter" data-level="6.1" data-path="prediction.html"><a href="prediction.html#prediction-with-regularized-regression-models"><i class="fa fa-check"></i><b>6.1</b> Prediction with Regularized Regression Models</a></li>
<li class="chapter" data-level="6.2" data-path="prediction.html"><a href="prediction.html#prediction-with-xgboost-model"><i class="fa fa-check"></i><b>6.2</b> Prediction with XGboost Model</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>7</b> Conclusion</a><ul>
<li class="chapter" data-level="7.1" data-path="conclusion.html"><a href="conclusion.html#answer-to-research-questions"><i class="fa fa-check"></i><b>7.1</b> Answer to Research Questions</a></li>
<li class="chapter" data-level="7.2" data-path="conclusion.html"><a href="conclusion.html#future-work"><i class="fa fa-check"></i><b>7.2</b> Future Work</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i><b>8</b> Bibliography</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">House Prices Advanced Regression Techniques</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prediction" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Prediction</h1>
<div id="prediction-with-regularized-regression-models" class="section level2">
<h2><span class="header-section-number">6.1</span> Prediction with Regularized Regression Models</h2>
<pre><code>## 15 Discrete Features: Id YearBuilt YearRemodAdd BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr TotRmsAbvGrd Fireplaces GarageYrBlt GarageCars MoSold YrSold20 Continous Feature: LotFrontage LotArea MasVnrArea BsmtFinSF1 BsmtFinSF2 BsmtUnfSF TotalBsmtSF X1stFlrSF X2ndFlrSF LowQualFinSF GrLivArea GarageArea WoodDeckSF OpenPorchSF EnclosedPorch X3SsnPorch ScreenPorch PoolArea MiscVal SalePrice23 Nominal Categorical Features: MSSubClass MSZoning Street Alley LandContour LotConfig Neighborhood Condition1 Condition2 BldgType HouseStyle RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType Foundation Heating CentralAir GarageType MiscFeature SaleType SaleCondition23 Ordered Categorical Features: LotShape Utilities LandSlope OverallQual OverallCond ExterQual ExterCond BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinType2 HeatingQC Electrical KitchenQual Functional FireplaceQu GarageFinish GarageQual GarageCond PavedDrive PoolQC Fence[1]  train-rmse:10.953498+0.002662   test-rmse:10.953500+0.011326 
## Multiple eval metrics are present. Will use test_rmse for early stopping.
## Will train until test_rmse hasn&#39;t improved in 10 rounds.
## 
## [2]  train-rmse:10.407027+0.002537   test-rmse:10.407029+0.011470 
## [3]  train-rmse:9.887894+0.002419    test-rmse:9.887896+0.011608 
## [4]  train-rmse:9.394737+0.002307    test-rmse:9.394738+0.011742 
## [5]  train-rmse:8.926258+0.002201    test-rmse:8.926259+0.011869 
## [6]  train-rmse:8.481207+0.002096    test-rmse:8.481372+0.012111 
## [7]  train-rmse:8.058389+0.001994    test-rmse:8.058555+0.011639 
## [8]  train-rmse:7.656692+0.001894    test-rmse:7.656859+0.011849 
## [9]  train-rmse:7.275063+0.001801    test-rmse:7.275431+0.011417 
## [10] train-rmse:6.912498+0.001711    test-rmse:6.912623+0.010976 
## [11] train-rmse:6.568046+0.001629    test-rmse:6.568478+0.010851 
## [12] train-rmse:6.240804+0.001547    test-rmse:6.240951+0.010706 
## [13] train-rmse:5.929916+0.001471    test-rmse:5.930394+0.010632 
## [14] train-rmse:5.634563+0.001398    test-rmse:5.634505+0.010604 
## [15] train-rmse:5.353969+0.001329    test-rmse:5.354346+0.010289 
## [16] train-rmse:5.087400+0.001263    test-rmse:5.087583+0.010231 
## [17] train-rmse:4.834158+0.001198    test-rmse:4.834051+0.010390 
## [18] train-rmse:4.593575+0.001139    test-rmse:4.593887+0.009861 
## [19] train-rmse:4.365023+0.001083    test-rmse:4.365229+0.009583 
## [20] train-rmse:4.147903+0.001030    test-rmse:4.147886+0.009588 
## [21] train-rmse:3.941640+0.000976    test-rmse:3.941590+0.009583 
## [22] train-rmse:3.745685+0.000930    test-rmse:3.745705+0.009580 
## [23] train-rmse:3.559526+0.000880    test-rmse:3.559161+0.009203 
## [24] train-rmse:3.382670+0.000831    test-rmse:3.382171+0.009355 
## [25] train-rmse:3.214658+0.000789    test-rmse:3.214105+0.009070 
## [26] train-rmse:3.055035+0.000754    test-rmse:3.054762+0.009103 
## [27] train-rmse:2.903400+0.000711    test-rmse:2.903178+0.009339 
## [28] train-rmse:2.759342+0.000675    test-rmse:2.759266+0.009237 
## [29] train-rmse:2.622475+0.000636    test-rmse:2.622701+0.009289 
## [30] train-rmse:2.492446+0.000593    test-rmse:2.492574+0.009357 
## [31] train-rmse:2.368930+0.000565    test-rmse:2.368912+0.009414 
## [32] train-rmse:2.251575+0.000549    test-rmse:2.251385+0.009793 
## [33] train-rmse:2.140104+0.000520    test-rmse:2.139894+0.009558 
## [34] train-rmse:2.034207+0.000489    test-rmse:2.034325+0.009486 
## [35] train-rmse:1.933595+0.000466    test-rmse:1.933504+0.009618 
## [36] train-rmse:1.838021+0.000442    test-rmse:1.837935+0.009536 
## [37] train-rmse:1.747226+0.000427    test-rmse:1.747222+0.009566 
## [38] train-rmse:1.660984+0.000395    test-rmse:1.661250+0.009462 
## [39] train-rmse:1.579069+0.000377    test-rmse:1.579350+0.009699 
## [40] train-rmse:1.501250+0.000364    test-rmse:1.501468+0.009740 
## [41] train-rmse:1.427334+0.000348    test-rmse:1.427608+0.009724 
## [42] train-rmse:1.357122+0.000329    test-rmse:1.357372+0.009754 
## [43] train-rmse:1.290431+0.000311    test-rmse:1.290948+0.009706 
## [44] train-rmse:1.227095+0.000305    test-rmse:1.227542+0.009601 
## [45] train-rmse:1.166930+0.000309    test-rmse:1.167430+0.009664 
## [46] train-rmse:1.109773+0.000313    test-rmse:1.110418+0.009641 
## [47] train-rmse:1.055510+0.000312    test-rmse:1.056204+0.009705 
## [48] train-rmse:1.003953+0.000291    test-rmse:1.004609+0.009401 
## [49] train-rmse:0.954989+0.000305    test-rmse:0.955836+0.009388 
## [50] train-rmse:0.908505+0.000308    test-rmse:0.909544+0.009386 
## [51] train-rmse:0.864328+0.000302    test-rmse:0.865553+0.009170 
## [52] train-rmse:0.822398+0.000306    test-rmse:0.823729+0.009069 
## [53] train-rmse:0.782591+0.000309    test-rmse:0.784122+0.008928 
## [54] train-rmse:0.744773+0.000315    test-rmse:0.746417+0.008772 
## [55] train-rmse:0.708864+0.000335    test-rmse:0.710733+0.008631 
## [56] train-rmse:0.674771+0.000340    test-rmse:0.676792+0.008518 
## [57] train-rmse:0.642397+0.000350    test-rmse:0.644716+0.008424 
## [58] train-rmse:0.611671+0.000363    test-rmse:0.614350+0.008328 
## [59] train-rmse:0.582489+0.000379    test-rmse:0.585387+0.008089 
## [60] train-rmse:0.554802+0.000405    test-rmse:0.557844+0.007957 
## [61] train-rmse:0.528515+0.000438    test-rmse:0.531768+0.007987 
## [62] train-rmse:0.503541+0.000451    test-rmse:0.507436+0.007835 
## [63] train-rmse:0.479847+0.000440    test-rmse:0.484284+0.007884 
## [64] train-rmse:0.457369+0.000446    test-rmse:0.462039+0.007809 
## [65] train-rmse:0.436032+0.000469    test-rmse:0.441179+0.007759 
## [66] train-rmse:0.415778+0.000474    test-rmse:0.421474+0.007806 
## [67] train-rmse:0.396563+0.000478    test-rmse:0.402679+0.007802 
## [68] train-rmse:0.378304+0.000493    test-rmse:0.384998+0.007727 
## [69] train-rmse:0.361010+0.000509    test-rmse:0.368250+0.007626 
## [70] train-rmse:0.344615+0.000519    test-rmse:0.352482+0.007567 
## [71] train-rmse:0.329046+0.000538    test-rmse:0.337491+0.007509 
## [72] train-rmse:0.314294+0.000534    test-rmse:0.323483+0.007389 
## [73] train-rmse:0.300291+0.000554    test-rmse:0.310218+0.007333 
## [74] train-rmse:0.287039+0.000564    test-rmse:0.297528+0.007181 
## [75] train-rmse:0.274457+0.000550    test-rmse:0.285703+0.007074 
## [76] train-rmse:0.262548+0.000551    test-rmse:0.274595+0.007097 
## [77] train-rmse:0.251266+0.000602    test-rmse:0.264129+0.007034 
## [78] train-rmse:0.240584+0.000613    test-rmse:0.254369+0.007087 
## [79] train-rmse:0.230480+0.000642    test-rmse:0.245206+0.007038 
## [80] train-rmse:0.220903+0.000670    test-rmse:0.236374+0.007032 
## [81] train-rmse:0.211861+0.000701    test-rmse:0.228288+0.006980 
## [82] train-rmse:0.203254+0.000708    test-rmse:0.220612+0.006813 
## [83] train-rmse:0.195151+0.000718    test-rmse:0.213478+0.006736 
## [84] train-rmse:0.187469+0.000705    test-rmse:0.206846+0.006694 
## [85] train-rmse:0.180213+0.000708    test-rmse:0.200539+0.006668 
## [86] train-rmse:0.173364+0.000730    test-rmse:0.194680+0.006611 
## [87] train-rmse:0.166874+0.000763    test-rmse:0.189286+0.006525 
## [88] train-rmse:0.160735+0.000805    test-rmse:0.184193+0.006434 
## [89] train-rmse:0.154921+0.000829    test-rmse:0.179433+0.006418 
## [90] train-rmse:0.149479+0.000854    test-rmse:0.175101+0.006402 
## [91] train-rmse:0.144336+0.000856    test-rmse:0.171043+0.006303 
## [92] train-rmse:0.139483+0.000921    test-rmse:0.167266+0.006210 
## [93] train-rmse:0.134862+0.000956    test-rmse:0.163805+0.006214 
## [94] train-rmse:0.130473+0.000948    test-rmse:0.160556+0.006201 
## [95] train-rmse:0.126380+0.000990    test-rmse:0.157546+0.006104 
## [96] train-rmse:0.122531+0.001017    test-rmse:0.154845+0.005983 
## [97] train-rmse:0.118931+0.001034    test-rmse:0.152217+0.005826 
## [98] train-rmse:0.115578+0.001052    test-rmse:0.149739+0.005760 
## [99] train-rmse:0.112366+0.001043    test-rmse:0.147436+0.005612 
## [100]    train-rmse:0.109314+0.001079    test-rmse:0.145427+0.005504 
## [101]    train-rmse:0.106473+0.001115    test-rmse:0.143636+0.005468 
## [102]    train-rmse:0.103867+0.001089    test-rmse:0.141874+0.005426 
## [103]    train-rmse:0.101354+0.001069    test-rmse:0.140297+0.005344 
## [104]    train-rmse:0.099028+0.001117    test-rmse:0.138833+0.005311 
## [105]    train-rmse:0.096839+0.001098    test-rmse:0.137570+0.005304 
## [106]    train-rmse:0.094805+0.001054    test-rmse:0.136295+0.005254 
## [107]    train-rmse:0.092885+0.001042    test-rmse:0.135233+0.005278 
## [108]    train-rmse:0.091067+0.001043    test-rmse:0.134260+0.005238 
## [109]    train-rmse:0.089406+0.001055    test-rmse:0.133389+0.005237 
## [110]    train-rmse:0.087738+0.001034    test-rmse:0.132444+0.005219 
## [111]    train-rmse:0.086227+0.001034    test-rmse:0.131624+0.005182 
## [112]    train-rmse:0.084791+0.001035    test-rmse:0.130840+0.005181 
## [113]    train-rmse:0.083434+0.000984    test-rmse:0.130097+0.005214 
## [114]    train-rmse:0.082178+0.000965    test-rmse:0.129512+0.005172 
## [115]    train-rmse:0.081006+0.000992    test-rmse:0.128944+0.005153 
## [116]    train-rmse:0.079896+0.000981    test-rmse:0.128416+0.005154 
## [117]    train-rmse:0.078860+0.000970    test-rmse:0.127933+0.005181 
## [118]    train-rmse:0.077855+0.000998    test-rmse:0.127476+0.005202 
## [119]    train-rmse:0.076890+0.000992    test-rmse:0.127017+0.005212 
## [120]    train-rmse:0.075970+0.000990    test-rmse:0.126728+0.005171 
## [121]    train-rmse:0.075147+0.001004    test-rmse:0.126367+0.005158 
## [122]    train-rmse:0.074300+0.001009    test-rmse:0.126011+0.005164 
## [123]    train-rmse:0.073515+0.000997    test-rmse:0.125725+0.005244 
## [124]    train-rmse:0.072737+0.000951    test-rmse:0.125451+0.005214 
## [125]    train-rmse:0.072030+0.000995    test-rmse:0.125222+0.005238 
## [126]    train-rmse:0.071333+0.001023    test-rmse:0.124928+0.005211 
## [127]    train-rmse:0.070672+0.001045    test-rmse:0.124678+0.005223 
## [128]    train-rmse:0.070039+0.001048    test-rmse:0.124509+0.005232 
## [129]    train-rmse:0.069458+0.001091    test-rmse:0.124378+0.005313 
## [130]    train-rmse:0.068888+0.001182    test-rmse:0.124222+0.005365 
## [131]    train-rmse:0.068351+0.001155    test-rmse:0.124061+0.005331 
## [132]    train-rmse:0.067799+0.001137    test-rmse:0.123878+0.005335 
## [133]    train-rmse:0.067282+0.001070    test-rmse:0.123718+0.005393 
## [134]    train-rmse:0.066808+0.001134    test-rmse:0.123649+0.005443 
## [135]    train-rmse:0.066353+0.001011    test-rmse:0.123494+0.005567 
## [136]    train-rmse:0.065917+0.000970    test-rmse:0.123389+0.005598 
## [137]    train-rmse:0.065432+0.000881    test-rmse:0.123264+0.005637 
## [138]    train-rmse:0.064958+0.000864    test-rmse:0.123180+0.005666 
## [139]    train-rmse:0.064510+0.000941    test-rmse:0.123115+0.005711 
## [140]    train-rmse:0.064169+0.000919    test-rmse:0.122997+0.005730 
## [141]    train-rmse:0.063687+0.000850    test-rmse:0.122962+0.005700 
## [142]    train-rmse:0.063311+0.000782    test-rmse:0.122891+0.005732 
## [143]    train-rmse:0.062984+0.000768    test-rmse:0.122841+0.005741 
## [144]    train-rmse:0.062638+0.000769    test-rmse:0.122715+0.005741 
## [145]    train-rmse:0.062291+0.000781    test-rmse:0.122663+0.005797 
## [146]    train-rmse:0.061941+0.000751    test-rmse:0.122614+0.005782 
## [147]    train-rmse:0.061664+0.000754    test-rmse:0.122546+0.005762 
## [148]    train-rmse:0.061290+0.000729    test-rmse:0.122474+0.005795 
## [149]    train-rmse:0.061028+0.000710    test-rmse:0.122407+0.005812 
## [150]    train-rmse:0.060742+0.000670    test-rmse:0.122370+0.005849 
## [151]    train-rmse:0.060512+0.000701    test-rmse:0.122330+0.005841 
## [152]    train-rmse:0.060188+0.000638    test-rmse:0.122257+0.005904 
## [153]    train-rmse:0.059867+0.000700    test-rmse:0.122229+0.005944 
## [154]    train-rmse:0.059528+0.000718    test-rmse:0.122175+0.005927 
## [155]    train-rmse:0.059106+0.000696    test-rmse:0.122148+0.005902 
## [156]    train-rmse:0.058870+0.000666    test-rmse:0.122145+0.005894 
## [157]    train-rmse:0.058633+0.000672    test-rmse:0.122058+0.005910 
## [158]    train-rmse:0.058340+0.000707    test-rmse:0.122022+0.005916 
## [159]    train-rmse:0.058092+0.000754    test-rmse:0.121986+0.005919 
## [160]    train-rmse:0.057842+0.000682    test-rmse:0.121972+0.005934 
## [161]    train-rmse:0.057591+0.000715    test-rmse:0.121918+0.005924 
## [162]    train-rmse:0.057254+0.000742    test-rmse:0.121823+0.005945 
## [163]    train-rmse:0.057007+0.000659    test-rmse:0.121833+0.005970 
## [164]    train-rmse:0.056737+0.000718    test-rmse:0.121818+0.005995 
## [165]    train-rmse:0.056405+0.000724    test-rmse:0.121707+0.006046 
## [166]    train-rmse:0.056100+0.000813    test-rmse:0.121631+0.006005 
## [167]    train-rmse:0.055787+0.000865    test-rmse:0.121579+0.006069 
## [168]    train-rmse:0.055573+0.000843    test-rmse:0.121614+0.006113 
## [169]    train-rmse:0.055377+0.000794    test-rmse:0.121600+0.006153 
## [170]    train-rmse:0.055147+0.000820    test-rmse:0.121558+0.006166 
## [171]    train-rmse:0.054912+0.000762    test-rmse:0.121549+0.006197 
## [172]    train-rmse:0.054658+0.000816    test-rmse:0.121519+0.006198 
## [173]    train-rmse:0.054451+0.000845    test-rmse:0.121506+0.006247 
## [174]    train-rmse:0.054259+0.000876    test-rmse:0.121521+0.006246 
## [175]    train-rmse:0.054025+0.000891    test-rmse:0.121488+0.006204 
## [176]    train-rmse:0.053732+0.000844    test-rmse:0.121478+0.006227 
## [177]    train-rmse:0.053487+0.000771    test-rmse:0.121460+0.006240 
## [178]    train-rmse:0.053300+0.000762    test-rmse:0.121454+0.006288 
## [179]    train-rmse:0.053150+0.000765    test-rmse:0.121432+0.006316 
## [180]    train-rmse:0.052921+0.000714    test-rmse:0.121413+0.006341 
## [181]    train-rmse:0.052697+0.000619    test-rmse:0.121376+0.006351 
## [182]    train-rmse:0.052447+0.000563    test-rmse:0.121362+0.006369 
## [183]    train-rmse:0.052269+0.000624    test-rmse:0.121342+0.006382 
## [184]    train-rmse:0.052119+0.000592    test-rmse:0.121364+0.006386 
## [185]    train-rmse:0.051854+0.000603    test-rmse:0.121337+0.006362 
## [186]    train-rmse:0.051673+0.000630    test-rmse:0.121329+0.006389 
## [187]    train-rmse:0.051421+0.000571    test-rmse:0.121329+0.006423 
## [188]    train-rmse:0.051206+0.000631    test-rmse:0.121326+0.006457 
## [189]    train-rmse:0.050970+0.000664    test-rmse:0.121316+0.006466 
## [190]    train-rmse:0.050775+0.000594    test-rmse:0.121289+0.006481 
## [191]    train-rmse:0.050630+0.000593    test-rmse:0.121284+0.006470 
## [192]    train-rmse:0.050451+0.000645    test-rmse:0.121280+0.006462 
## [193]    train-rmse:0.050239+0.000732    test-rmse:0.121299+0.006498 
## [194]    train-rmse:0.050052+0.000774    test-rmse:0.121256+0.006506 
## [195]    train-rmse:0.049875+0.000744    test-rmse:0.121239+0.006504 
## [196]    train-rmse:0.049656+0.000824    test-rmse:0.121238+0.006508 
## [197]    train-rmse:0.049428+0.000871    test-rmse:0.121213+0.006518 
## [198]    train-rmse:0.049213+0.000905    test-rmse:0.121228+0.006514 
## [199]    train-rmse:0.048989+0.000911    test-rmse:0.121195+0.006489 
## [200]    train-rmse:0.048837+0.000880    test-rmse:0.121204+0.006492 
## [201]    train-rmse:0.048618+0.000821    test-rmse:0.121196+0.006510 
## [202]    train-rmse:0.048401+0.000904    test-rmse:0.121195+0.006510 
## [203]    train-rmse:0.048241+0.000913    test-rmse:0.121195+0.006515 
## [204]    train-rmse:0.048009+0.000934    test-rmse:0.121202+0.006520 
## [205]    train-rmse:0.047814+0.000952    test-rmse:0.121196+0.006518 
## [206]    train-rmse:0.047621+0.000924    test-rmse:0.121186+0.006538 
## [207]    train-rmse:0.047467+0.000987    test-rmse:0.121220+0.006555 
## [208]    train-rmse:0.047159+0.000939    test-rmse:0.121216+0.006536 
## [209]    train-rmse:0.047003+0.000986    test-rmse:0.121194+0.006515 
## [210]    train-rmse:0.046851+0.001006    test-rmse:0.121211+0.006532 
## [211]    train-rmse:0.046560+0.001004    test-rmse:0.121186+0.006565 
## [212]    train-rmse:0.046400+0.001020    test-rmse:0.121196+0.006605 
## [213]    train-rmse:0.046185+0.001069    test-rmse:0.121201+0.006624 
## [214]    train-rmse:0.045946+0.000943    test-rmse:0.121202+0.006649 
## [215]    train-rmse:0.045717+0.000941    test-rmse:0.121172+0.006646 
## [216]    train-rmse:0.045559+0.000923    test-rmse:0.121201+0.006673 
## [217]    train-rmse:0.045425+0.000946    test-rmse:0.121198+0.006683 
## [218]    train-rmse:0.045215+0.001012    test-rmse:0.121201+0.006679 
## [219]    train-rmse:0.045004+0.001003    test-rmse:0.121209+0.006691 
## [220]    train-rmse:0.044800+0.001056    test-rmse:0.121243+0.006718 
## [221]    train-rmse:0.044626+0.001107    test-rmse:0.121258+0.006728 
## [222]    train-rmse:0.044475+0.001128    test-rmse:0.121241+0.006707 
## [223]    train-rmse:0.044302+0.001122    test-rmse:0.121251+0.006731 
## [224]    train-rmse:0.044079+0.001115    test-rmse:0.121248+0.006746 
## [225]    train-rmse:0.043937+0.001128    test-rmse:0.121237+0.006755 
## Stopping. Best iteration:
## [215]    train-rmse:0.045717+0.000941    test-rmse:0.121172+0.006646
## 
## The XGB model includes 71 features, and  the optimal number of rounds: 215 was selected based on  RMSE of 0.121172</code></pre>
<pre><code>## [1] 113867.4 157183.7 177970.1 197784.8 189829.9 170346.0</code></pre>
</div>
<div id="prediction-with-xgboost-model" class="section level2">
<h2><span class="header-section-number">6.2</span> Prediction with XGboost Model</h2>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" data-line-number="1"><span class="co">#Prediction</span></a>
<a class="sourceLine" id="cb102-2" data-line-number="2">XGBpred_fs &lt;-<span class="st"> </span><span class="kw">predict</span>(xgb_mod_fs, dtest_fs)</a>
<a class="sourceLine" id="cb102-3" data-line-number="3">predictions_XGB_fs &lt;-<span class="st"> </span><span class="kw">exp</span>(XGBpred_fs) <span class="co">#reverse the log to the real values</span></a>
<a class="sourceLine" id="cb102-4" data-line-number="4"><span class="kw">head</span>(predictions_XGB_fs)</a></code></pre></div>
<pre><code>## [1] 123398.8 163053.9 192411.7 183921.2 193044.5 170095.6</code></pre>
<p><strong>Store the item IDs and class labels in a csv file</strong></p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" data-line-number="1">Ridge_model_final_data2&lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;ID&quot;</span>=test_final<span class="op">$</span>Id,<span class="st">&quot;SalePrice&quot;</span>=pred_ridge_test_final)</a>
<a class="sourceLine" id="cb104-2" data-line-number="2"><span class="kw">write.csv</span>(Ridge_model_final_data2, <span class="st">&quot;Ridge_ModelFinal2&quot;</span>, <span class="dt">row.names=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb104-3" data-line-number="3"></a>
<a class="sourceLine" id="cb104-4" data-line-number="4">Lasso_model_final_data2&lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;ID&quot;</span>=test_final<span class="op">$</span>Id,<span class="st">&quot;SalePrice&quot;</span>=pred_lasso_test_final)</a>
<a class="sourceLine" id="cb104-5" data-line-number="5"><span class="kw">write.csv</span>(Lasso_model_final_data2, <span class="st">&quot;Lasso_ModelFinal2&quot;</span>, <span class="dt">row.names=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb104-6" data-line-number="6"></a>
<a class="sourceLine" id="cb104-7" data-line-number="7">ElasticNet_model_final_data2&lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;ID&quot;</span>=test_final<span class="op">$</span>Id,<span class="st">&quot;SalePrice&quot;</span>=pred_net_test_final)</a>
<a class="sourceLine" id="cb104-8" data-line-number="8"><span class="kw">write.csv</span>(ElasticNet_model_final_data2, <span class="st">&quot;ElasticNet_ModelFinal2&quot;</span>, <span class="dt">row.names=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb104-9" data-line-number="9"></a>
<a class="sourceLine" id="cb104-10" data-line-number="10">xgbmodel_pred_d2_fs&lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;ID&quot;</span>=test_ID,<span class="st">&quot;SalePrice&quot;</span>=predictions_XGB_fs)</a>
<a class="sourceLine" id="cb104-11" data-line-number="11"><span class="kw">write.csv</span>(xgbmodel_pred_d2_fs, <span class="st">&quot;xgbModel_fs_outl&quot;</span>, <span class="dt">row.names=</span><span class="ot">FALSE</span>) </a></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modeling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["House_Prices_Project.pdf", "House_Prices_Project.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
